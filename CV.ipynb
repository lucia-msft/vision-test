{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Computer Vision Scenarios"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "from IPython.display import display\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "KEY = os.getenv('CV_KEY')\n",
    "ENDPOINT = os.getenv('CV_ENDPOINT')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n"
   ]
  },
  {
   "source": [
    "## Describe Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "source": [
    "## Analyze Image "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===== Analyze an image - remote =====\nCategories from remote image: \n&#39;building_&#39; with confidence 31.64%\n&#39;others_&#39; with confidence 0.39%\n&#39;outdoor_&#39; with confidence 3.91%\n"
    }
   ],
   "source": [
    "print(\"===== Analyze an image - remote =====\")\n",
    "\n",
    "features = [\"categories\", \"tags\", \"faces\", \"imagetype\", \"color\", \"adult\", \"objects\", \"brands\"]\n",
    "\n",
    "# Call API with URL and features\n",
    "results_remote = computervision_client.analyze_image(url=remote_image_url, visual_features=features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Detecting brands in remote image: \nNo brands detected.\n"
    }
   ],
   "source": [
    "print(\"Detecting brands in remote image: \")\n",
    "if len(results_remote.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in results_remote.brands:\n",
    "        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n",
    "        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n",
    "        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Analyzing remote image for adult or racy content ... \nIs adult content: False with confidence 0.34\nHas racy content: False with confidence 0.49\n"
    }
   ],
   "source": [
    "    # Print results with adult/racy score\n",
    "    print(\"Analyzing remote image for adult or racy content ... \")\n",
    "    print(\"Is adult content: {} with confidence {:.2f}\".format(results_remote.adult.is_adult_content, results_remote.adult.adult_score * 100))\n",
    "    print(\"Has racy content: {} with confidence {:.2f}\".format(results_remote.adult.is_racy_content, results_remote.adult.racy_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Faces in the remote image: \nNo faces detected.\n"
    }
   ],
   "source": [
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Getting color scheme of the remote image: \nIs black and white: False\nAccent color: 486A83\nDominant background color: White\nDominant foreground color: Grey\nDominant colors: [&#39;Grey&#39;, &#39;White&#39;]\n"
    }
   ],
   "source": [
    "'''\n",
    "Detect Color - remote\n",
    "This example detects the different aspects of its color scheme in a remote image.\n",
    "'''\n",
    "# Print results of color scheme\n",
    "print(\"Getting color scheme of the remote image: \")\n",
    "print(\"Is black and white: {}\".format(results_remote.color.is_bw_img))\n",
    "print(\"Accent color: {}\".format(results_remote.color.accent_color))\n",
    "print(\"Dominant background color: {}\".format(results_remote.color.dominant_color_background))\n",
    "print(\"Dominant foreground color: {}\".format(results_remote.color.dominant_color_foreground))\n",
    "print(\"Dominant colors: {}\".format(results_remote.color.dominant_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prints type results with degree of accuracy\n",
    "print(\"Type of remote image:\")\n",
    "if results_remote.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not clip art.\")\n",
    "elif results_remote.image_type.line_drawing_type == 1:\n",
    "    print(\"Image is ambiguously clip art.\")\n",
    "elif results_remote.image_type.line_drawing_type == 2:\n",
    "    print(\"Image is normal clip art.\")\n",
    "else:\n",
    "    print(\"Image is good clip art.\")\n",
    "\n",
    "if results_remote.image_type.line_drawing_type == 0:\n",
    "    print(\"Image is not a line drawing.\")\n",
    "else:\n",
    "    print(\"Image is a line drawing\")"
   ]
  },
  {
   "source": [
    "## Get Specific Landmark "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_remote = computervision_client.analyze_image_by_domain(\"landmarks\", url=remote_image_url)\n",
    "\n",
    "print(\"Landmarks in the remote image:\")\n",
    "if len(results_remote.result[\"landmarks\"]) == 0:\n",
    "    print(\"No landmarks detected.\")\n",
    "else:\n",
    "    for lm in results_remote.result[\"landmarks\"]:\n",
    "        print(lm[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}